{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_test_puntoCorte.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhJfT_RgC6EH"
      },
      "source": [
        "# Cargo librerías\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpWceFVYC_Z4"
      },
      "source": [
        "import numpy as np #manejo de arreglos\n",
        "\n",
        "import matplotlib.pyplot as plt #gráficos\n",
        "\n",
        "from sklearn.decomposition import PCA #Componentes principales\n",
        "from sklearn.preprocessing import StandardScaler #Escalado de datos\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #regresión logística\n",
        "\n",
        "# matriz de confusión: https://es.wikipedia.org/wiki/Matriz_de_confusi%C3%B3n\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# métricas para evaluar la clasificación predicha\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "# otras métricas se pueden ver acá: https://scikit-learn.org/stable/modules/model_evaluation.html#\n",
        "\n",
        "# divide en conjuntos para entrenar y para testeat\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tamaño de gráficos\n",
        "plt.rcParams[\"figure.figsize\"] = (8,8)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNjN9_f2MYM"
      },
      "source": [
        "# Levanto datos, train/test split, evaluaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp7WhyJqEc6o",
        "outputId": "84d1f323-ed80-4ef4-9563-c38cf879bc09"
      },
      "source": [
        "# Levanto los datos\n",
        "datos = np.loadtxt('./heart.csv',delimiter=',', skiprows=1)#, usecols = (0,2,3,4,5,6,7,8) )\n",
        "nombres = ['age','sex','cp','rbs','sc','fbs120','recr','mhr','eia','op','slope','ca','thal']\n",
        "\n",
        "# extraigo variables (predictoras, features, características, son todos nombres que se usan)\n",
        "X = datos[:,0:-1]\n",
        "# extraigo clasificación (target, labels, etiquetas, son todos nombres que se usan)\n",
        "y = datos[:,-1]\n",
        "\n",
        "\n",
        "# Separo en train/test. El stratify es para conservar el balance de clases.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=474077)\n",
        "\n",
        "#IMPORTANTE: sigue estando el problema que el split influye mucho en la predicción (recordar encuentro virtual con nros. primos). \n",
        "# Para resolver, o mejor dicho amortiguar este efecto, se hace Cross Validation (Validación Cruzada), que por ahora queda en el tintero.\n",
        "# La solución de compromiso que usamos es fijar el random_state para hacer comparables las métricas entre diferentes corridas.\n",
        "# De todos modos, puede pensar por su cuenta alguna estrategia para amortiguar el efecto que vimos de la gran variabilidad\n",
        "# que tiene la predicción dependiendo del split aleatorio que se use.\n",
        "\n",
        "\n",
        "# Standarizo datos de ENTRENAMIENTO\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) #calcula promedio y desvío\n",
        "# print(\"Promedio datos entrenamiento\", scaler.mean_)\n",
        "# print(\"Varianza datos entrenamiento\", scaler.var_)\n",
        "X_train = scaler.transform(X_train) #estandariza con promedio y desvío anteriores\n",
        "\n",
        "# Standarizo datos de TESTEO con los mismos promedio y desvío calculados para entrenamiento\n",
        "X_test = scaler.transform(X_test)\n",
        "# ¿Por qué hago esto? Porque en teoría los datos de entrenamientos son desconocidos a la hora de entrenar el modelo.\n",
        "\n",
        "\n",
        "\n",
        "lg = LogisticRegression() #instancio la clase\n",
        "#entreno modelo predictivo a partir de los datos de ENTRENAMIENTO\n",
        "modelo_lg = lg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# clasifico según el modelo, es decir predigo las clases, con los datos de TESTEO.\n",
        "# por defecto clasifica por probabilidad más alta (o sea punto de corte 0.5)\n",
        "y_pred_test = modelo_lg.predict(X_test) \n",
        "\n",
        "\n",
        "# métricas de evaluación sobre los datos de TESTEO.\n",
        "accuracy = accuracy_score(y_test, y_pred_test)\n",
        "recall = recall_score(y_test, y_pred_test)\n",
        "precision = precision_score(y_test, y_pred_test)\n",
        "\n",
        "print('Métricas sobre datos nuevos de TEST')\n",
        "print('Accuracy: ', round(accuracy,2))\n",
        "print('Recall: ', round(recall,2))\n",
        "print('Precision: ', round(precision,2))\n",
        "\n",
        "\n",
        "\n",
        "# predigo probabilidades según el modelo con los datos de TESTEO.\n",
        "# Luego uso estas probabilidades para, mediante punto de corte, clasificar en clases.\n",
        "probas = modelo_lg.predict_proba(X_test)\n",
        "\n",
        "# por ejemplo, por defecto asumo que SÍ tiene riesgo cardíco (y=1)\n",
        "y_pred_test_custom = np.ones(y_test.shape)\n",
        "\n",
        "#y si la probabilidad de y=0 es mayor a 0.8, lo clasifico como sin riesgo (y=0)\n",
        "for i in range(probas.shape[0]):\n",
        "    if (probas[i,0]>0.8):\n",
        "        y_pred_test_custom[i]=0.\n",
        "\n",
        "\n",
        "#métricas de evaluación sobre los datos de TESTEO, punto de corte arbitrario\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_test_custom)\n",
        "recall_custom = recall_score(y_test, y_pred_test_custom)\n",
        "precision_custom = precision_score(y_test, y_pred_test_custom)\n",
        "\n",
        "print('')\n",
        "print('Métricas sobre datos nuevos de TEST, punto de corte arbitrario')\n",
        "print('Accuracy: ', round(accuracy_custom,2))\n",
        "print('Recall: ', round(recall_custom,2))\n",
        "print('Precision: ', round(precision_custom,2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas sobre datos nuevos de TEST\n",
            "Accuracy:  0.85\n",
            "Recall:  0.9\n",
            "Precision:  0.83\n",
            "\n",
            "Métricas sobre datos nuevos de TEST, punto de corte arbitrario\n",
            "Accuracy:  0.78\n",
            "Recall:  0.92\n",
            "Precision:  0.74\n"
          ]
        }
      ]
    }
  ]
}